"""
Rules to identify SV candidates from read alignments confirmation by for local
assembly.
"""
import os

SNAKEMAKE_DIR = os.path.dirname(workflow.snakefile)
CANDIDATES = config.get("candidates", "filtered_assembly_candidates_with_coverage.bed")
REGIONS_TO_EXCLUDE = config.get("regions_to_exclude")
if REGIONS_TO_EXCLUDE == "None":
    REGIONS_TO_EXCLUDE = None
BANDWIDTH_LIMIT = 50000

# Load alignments if they already exist.
if config.get("alignments") and os.path.exists(config.get("alignments")):
    with open(config["alignments"], "r") as fh:
        ALIGNMENTS = sorted([line.rstrip() for line in fh])

    PATHS_BY_ALIGNMENT_NAME = dict([(os.path.basename(alignment).rstrip(".bam"), alignment) for alignment in ALIGNMENTS])
    ALIGNMENT_NAMES = sorted(PATHS_BY_ALIGNMENT_NAME.keys())
else:
    ALIGNMENT_NAMES = []

def _get_bam_path_for_batch(wildcards):
    return PATHS_BY_ALIGNMENT_NAME.get(wildcards.alignment_name)

# Annotate assembly candidates with coverage.
rule get_regions:
    input: "assembly_candidates_with_coverage.bed"
    output: CANDIDATES
    params: min_coverage=str(config.get("min_coverage")), max_coverage=str(config.get("max_coverage")), max_length=str(config.get("max_candidate_length"))
    run:
        if REGIONS_TO_EXCLUDE is not None:
            shell("set -o pipefail; bedtools intersect -a {input} -b %s -wa -v | awk '$4 >= {params.min_coverage} && $4 <= {params.max_coverage} && $3 - $2 <= {params.max_length}' > {output}" % REGIONS_TO_EXCLUDE)
        else:
            shell("awk '$4 >= {params.min_coverage} && $4 <= {params.max_coverage} && $3 - $2 <= {params.max_length}' {input} > {output}")

# Annotate assembly candidates with coverage.
rule annotate_coverage_for_candidates:
    input: candidates="assembly_candidates_and_windows.bed", coverage="coverage.bed"
    output: "assembly_candidates_with_coverage.bed"
    shell: """bedtools intersect -a {input.candidates} -b {input.coverage} -sorted -wao | awk 'OFS="\\t" {{ if ($7 == ".") {{ $7 = 0 }} print }}' | groupBy -i stdin -g 1,2,3 -c 7 -o mean > {output}"""

# Merge filtered candidates with tiled windows.
rule merge_filtered_candidates_with_tiled_windows:
    input: "assembly_candidates.bed", "windows_for_tiled_assembly.bed"
    output: "assembly_candidates_and_windows.bed"
    shell: "sort -k 1,1 -k 2,2n -m {input} > {output}"

# Merge filtered candidates.
rule merge_filtered_candidates:
    input: "filtered_candidates.tab", "merged_hardstops_per_bin.bed", chromosome_lengths=CHROMOSOME_LENGTHS
    output: "assembly_candidates.bed"
    # TODO: consider moving these parameters into config file
    params: merge_distance="500", slop="10000"
    shell: "set -o pipefail; cut -f 1-3 {input[0]} {input[1]} | sort -k 1,1 -k 2,2n | bedtools merge -i stdin -d {params.merge_distance} | bedtools slop -i stdin -g {input.chromosome_lengths} -b {params.slop} > {output}"

#
# Windows for tiled assemblies.
#

rule create_windows_for_tiled_assemblies:
    input: CHROMOSOME_LENGTHS
    output: "windows_for_tiled_assembly.bed"
    params: window=str(config.get("assembly_window_size")), slide=str(config.get("assembly_window_slide"))
    shell: "bedtools makewindows -g {input} -w {params.window} -s {params.slide} | sort -k 1,1 -k 2,2n > {output}"

#
# Inaccessible regions
#

rule identify_inaccessible_regions:
    input: coverage="coverage.bed", excluded_regions="regions_to_exclude_as_inaccessible.bed"
    output: "inaccessible_regions.bed"
    params: max_support=str(config.get("max_inaccessible_support"))
    shell:
        "awk '$4 <= {params.max_support}' {input.coverage} | "
            "bedtools merge -i stdin -d 1000 | "
            "bedtools intersect -a stdin -b {input.excluded_regions} -v > {output}"

rule collect_regions_to_exclude_as_inaccessible_regions:
    input: "merged_hardstops_per_bin.bed", "gaps_in_reference_assembly.bed", "filtered_candidates.tab"
    output: "regions_to_exclude_as_inaccessible.bed"
    shell: "cut -f 1-3 {input} | sort -k 1,1 -k 2,2n | bedtools merge -i stdin -d 1 > {output}"

#
# Hardstops (all classes)
#

# Filter hardstops to exclude reference gaps and small SV candidates. Then merge
# adjacent bins that pass filters.
rule filter_and_merge_adjacent_hardstop_bins:
    input: hardstops="hardstops_per_bin.bed", gaps="gaps_in_reference_assembly.bed", small_svs="filtered_candidates.tab"
    output: "merged_hardstops_per_bin.bed"
    params: min_support=str(config.get("min_hardstop_support"))
    shell:
        "awk '$4 > {params.min_support}' {input.hardstops} | "
            "bedtools window -w 1000 -a stdin -b {input.gaps} -v | "
            "bedtools window -w 1000 -a stdin -b {input.small_svs} -v | "
            "bedtools merge -i stdin -d 1 > {output}"

# Find gap bases in the reference assembly to exclude from hardstop collection.
rule identify_gaps_in_reference_assembly:
    input: config["reference"]
    output: "gaps_in_reference_assembly.bed"
    shell: "python {SNAKEMAKE_DIR}/scripts/find_fasta_gaps.py {input} > {output}"

# Count hardstops per genomic bin.
rule count_hardstops_per_genomic_bin:
    input: hardstops="hardstop_breakpoints.bed", bins="hardstop_bins.bed"
    output: "hardstops_per_bin.bed"
    shell: "bedtools intersect -a {input.bins} -b {input.hardstops} -sorted -c > {output}"

# Create hardstop breakpoints from hardstop locations (either left, right, or
# both). If a read is clipped on the left, use its start position as the
# breakpoint. If it is clipped on the right, use its end position. If a read is
# clipped from both sides, print two separate breakpoints using these same rules
# for left and right breakpoints.
rule create_hardstop_breakpoints:
    input: "hardstops.bed"
    output: "hardstop_breakpoints.bed"
    shell: """awk 'OFS="\\t" {{
                  if ($6 == "left") {{ print $1,$2,$2 + 1,$4,$7,"left" }}
                  else if ($6 == "right") {{ print $1,$3 - 1,$3,$4,$8,"right" }}
                  else if ($6 == "both") {{ print $1,$2,$2 + 1,$4,$7,"left"; print $1,$3 - 1,$3,$4,$8,"right" }}
              }}' {input} | sort -k 1,1 -k 2,2n > {output}"""

# Collect gaps in one command
rule collect_hardstops:
    input: expand("hardstops_in_aligned_reads/{alignment_name}.bed", alignment_name=ALIGNMENT_NAMES)
    output: "hardstops.bed"
    shell: "sort -k 1,1 -k 2,2n -m {input} > {output}"

# Parse CIGAR string of aligned reads for clipped alignments.
rule find_hardstops_in_aligned_reads:
    input: alignments=_get_bam_path_for_batch
    output: "hardstops_in_aligned_reads/{alignment_name}.bed"
    params: mapping_quality_threshold=str(config.get("mapping_quality")), min_clipping="500"
    shell:
        "{SNAKEMAKE_DIR}/scripts/mcst/hardstop {input} {params.mapping_quality_threshold} {params.min_clipping} {output}; "
        "sort -k 1,1 -k 2,2n -o {output} {output}"

rule create_genomic_bins:
    input: CHROMOSOME_LENGTHS
    output: "hardstop_bins.bed"
    params: bin_size="500"
    shell: "bedtools makewindows -g {input} -w {params.bin_size} | sort -k 1,1 -k 2,2n > {output}"

#
# Small SVs (insertions and deletions)
#

# Plot candidate summary.
rule plot_candidate_summary:
    input: "sv_candidate_summary.tab"
    output: lengths="sv_candidate_lengths.pdf", support="sv_candidate_support.pdf"
    shell: "Rscript {SNAKEMAKE_DIR}/scripts/plot_SV_candidate_summary.R {input} {output.lengths} {output.support}"

# Summarize filtered candidates by event attributes.
rule summarize_filtered_candidates:
    input: expand("filtered_candidates_for_{event_type}.bed", event_type=EVENT_TYPES)
    output: "sv_candidate_summary.tab"
    shell: """awk 'OFS="\\t" {{ if (NR == 1) {{ print "event_type","mean_length","support" }} print $4,$5,$6 }}' {input} > {output}"""

# Summarize filtered candidates by event attributes.
rule combine_filtered_candidates:
    input: expand("filtered_candidates_for_{event_type}.bed", event_type=EVENT_TYPES)
    output: "filtered_candidates.tab"
    shell: "sort -k 1,1 -k 2,2n -m {input} | cut -f 1-4,6 > {output}"

# Filter candidates by support and coverage.
rule filter_candidates:
    input: "coverage_and_merged_support_for_{event_type}.bed"
    output: "filtered_candidates_for_{event_type}.bed"
    params:
        min_support=str(config.get("min_support")),
        max_support=str(config.get("max_support")),
        min_length=str(config.get("min_length")),
        min_coverage=str(config.get("min_coverage")),
        max_coverage=str(config.get("max_coverage"))
    run:
        shell("awk '$4 >= {params.min_length} && $5 >= {params.min_support} && $5 <= {params.max_support} && $9 >= {params.min_coverage} && $9 <= {params.max_coverage}' {input} > {output}.tmp")
        if os.stat("%s.tmp" % output[0]).st_size > 0:
            shell("bedtools merge -i {output}.tmp -d 1 -c 6,4,5 -o distinct,mean,mean > {output}")
        else:
            shell("touch {output}")

        shell("rm -f {output}.tmp")

# Annotate merged gap support with alignment coverage.
rule annotate_coverage_of_merged_gap_support:
    input: support="merged_support_for_{event_type}.bed", coverage="coverage.bed"
    output: "coverage_and_merged_support_for_{event_type}.bed"
    shell: """set -e; set -o pipefail; bedtools intersect -a {input.support} -b {input.coverage} -sorted -wao | awk 'OFS="\\t" {{ if ($13 == ".") {{ $13 = 0 }} print }}' | cut -f 1-6,8- | groupBy -i stdin -g 1,2,3,4,5,6,7,8 -c 12 -o mean > {output}"""

# Merge gap support for each type of event.
rule merge_gap_support_from_aligned_reads:
    input: expand("aligned_reads_{{event_type}}/{alignment_name}.bed", alignment_name=ALIGNMENT_NAMES)
    output: "merged_support_for_{event_type}.bed"
    shell: "set -o pipefail; sort -k 1,1 -k 2,2n -m {input} | python {SNAKEMAKE_DIR}/scripts/PrintGapSupport.py /dev/stdin /dev/stdout | sort -k 1,1 -k 2,2n -k 3,3n -k 4,4n -k 5,5n -k 6,6 -k 7,7 -k 8,8 -k 9,9 > {output}"

# Classify insertions and deletions into their own output files.
rule classify_gaps_in_aligned_reads:
    input: "gaps_in_aligned_reads/{alignment_name}.bed"
    output: "aligned_reads_{event_type}/{alignment_name}.bed"
    shell: """awk '$4 == "{wildcards.event_type}"' {input} | sort -k 1,1 -k 2,2n > {output}"""

# Parse CIGAR string of aligned reads for insertions and deletions.
rule find_gaps_in_aligned_reads:
    input: alignments=_get_bam_path_for_batch, reference=config["reference"]
    output: "gaps_in_aligned_reads/{alignment_name}.bed"
    log: "gaps_in_aligned_reads/{alignment_name}.log"
    params: mapping_quality_threshold=str(config.get("mapping_quality"))
    shell:
        "samtools view -F 0x4 -q {params.mapping_quality_threshold} {input.alignments} "
            "| python {SNAKEMAKE_DIR}/scripts/PrintGaps.py {input.reference} /dev/stdin --tsd 0 --condense 20 > {output} 2> {log}"

# Collect coverages from all alignments.
rule merge_coverage_per_batch:
    input: expand("coverage/{alignment_name}.bed", alignment_name=ALIGNMENT_NAMES)
    output: "coverage.bed"
    shell: """paste {input} | awk 'OFS="\\t" {{ sum = 0; for (i = 4; i <= NF; i++) {{ if (i % 4 == 0) {{ sum += $i }} }} print $1,$2,$3,sum }}' | sort -k 1,1 -k 2,2n > {output}"""

# Calculate coverage from each batch.
rule calculate_coverage_per_batch:
    input: _get_bam_path_for_batch
    output: "coverage/{alignment_name}.bed"
    shell: "{SNAKEMAKE_DIR}/scripts/mcst/coverage {output} -in {input}"
