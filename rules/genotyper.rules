import json
import os
import pandas as pd
import pysam
import tempfile

SNAKEMAKE_DIR = os.path.dirname(workflow.snakefile)

SSD_TMP_DIR = "/data/scratch/ssd"
if os.path.exists(SSD_TMP_DIR):
    TMPDIR = SSD_TMP_DIR
else:
    TMPDIR = tempfile.gettempdir()

FINAL_GENOTYPES = config["genotyped_variants"]
CONFIG_FILE = config["genotyper_config"]
THREADS = config["threads"]
with open(CONFIG_FILE, "r") as CONFIG_FILE_FH:
    GENOTYPER_CONFIG = json.load(CONFIG_FILE_FH)

SAMPLES = sorted(GENOTYPER_CONFIG["samples"].keys())
SLOP_FOR_SV_SEQUENCE_POSITIONS = 5000
HOMOZYGOUS_BINOMIAL_PROBABILITY = GENOTYPER_CONFIG.get("homozygous_binomial_probability", 0.95)
HETEROZYGOUS_BINOMIAL_PROBABILITY = GENOTYPER_CONFIG.get("heterozygous_binomial_probability", 0.5)

def _get_bam_for_sample(wildcards):
    return GENOTYPER_CONFIG["samples"][wildcards.sample]

def _get_sv_sequence_regions_for_sample(wildcards):
    if "sample_bam_reference" in config and GENOTYPER_CONFIG["sample_bam_reference"].get(wildcards.sample):
        reference = GENOTYPER_CONFIG["sample_bam_reference"].get(wildcards.sample)
    else:
        reference = GENOTYPER_CONFIG["default_bam_reference"]

    return "sv_sequences_in_reference/%s.bed" % reference

def _get_reference_path_by_sample(wildcards):
    if "sample_bam_reference" in GENOTYPER_CONFIG and GENOTYPER_CONFIG["sample_bam_reference"].get(wildcards.sample):
        reference = GENOTYPER_CONFIG["sample_bam_reference"].get(wildcards.sample)
    else:
        reference = GENOTYPER_CONFIG["default_bam_reference"]

    return GENOTYPER_CONFIG["bam_reference"][reference]

rule convert_genotypes_to_vcf:
    input: genotypes="genotypes_by_all_samples.tab", calls="sv_calls.vcf.gz", reference=GENOTYPER_CONFIG["sv_reference"]
    output: FINAL_GENOTYPES
    shell: "python {SNAKEMAKE_DIR}/scripts/genotypes_to_vcf.py {input.genotypes} {input.calls} {input.reference} /dev/stdout | vcffixup - | bgzip -c > {output}; tabix -p vcf {output}"

rule genotype_across_all_samples:
    input: "genotypes.tab", GENOTYPER_CONFIG["sample_manifest"]
    output: "genotypes_by_all_samples.tab"
    shell: "python {SNAKEMAKE_DIR}/scripts/regenotype.py --homozygous_binomial_probability={HOMOZYGOUS_BINOMIAL_PROBABILITY} --heterozygous_binomial_probability={HETEROZYGOUS_BINOMIAL_PROBABILITY} {input} {output}"

rule merge_per_sample_genotypes:
    input: expand("samples/{sample}/genotypes.tab", sample=SAMPLES)
    output: "genotypes.tab"
    shell: "head -n 1 {input[0]} > {output}; for file in {input}; do sed 1d $file; done >> {output}"

rule plot_genotypes:
    input: "samples/{sample}/genotypes.tab"
    output: "samples/{sample}/genotypes.pdf"
    shell: "Rscript plot_genotypes.R {input} {output} {wildcards.sample}"

rule genotype_PacBio_SVs:
    input: "samples/{sample}/concordant_support.tab", GENOTYPER_CONFIG["sample_manifest"]
    output: "samples/{sample}/genotypes.tab"
    shell: "python {SNAKEMAKE_DIR}/scripts/regenotype.py {input} {output}"

rule calculate_depth_across_PacBio_SVs:
    input: sv_calls="sv_calls.vcf.gz", alignments="samples/{sample}/alignments.bam"
    output: "samples/{sample}/concordant_support.tab"
    log: "samples/{sample}/concordant_support.log"
    benchmark: "benchmarks/concordant_support/{sample}.txt"
    shell: "python {SNAKEMAKE_DIR}/scripts/genotype.py {input.sv_calls} {input.alignments} > {output} 2> {log}"

#
# Map reads.
#

# Map paired-end reads with BWA MEM
rule map_sample_reads:
    input:
        regions=_get_sv_sequence_regions_for_sample,
        bam=_get_bam_for_sample,
        bam_reference=_get_reference_path_by_sample,
        sv_reference="sv_reference.fasta",
        sv_index="sv_reference.fasta.bwt",
        alts="local_assemblies_for_genotyping.sam"
    output:
        alignments="samples/{sample}/alignments.bam"
    benchmark:
        "benchmarks/map_sample_reads/{sample}.txt"
    log:
        "samples/{sample}/alignments.log"
    shell:
        """{{
    while read line; do set -- $line; samtools view {input.bam} $1:$2-$3; done < {input.regions} | samtools view -S -t {input.bam_reference}.fai -u -b - | samtools bamshuf -n 32 -O - {TMPDIR}/shuffled_reads.{wildcards.sample} | samtools bam2fq - | seqtk dropse -;
    samtools view {input.bam} '*' | samtools bam2fq - | python {SNAKEMAKE_DIR}/scripts/filter_fastq_with_Ns.py --proportion_of_Ns_allowed=0.05 /dev/stdin | seqtk dropse -;
}} | bwa mem -R '@RG\\tID:{wildcards.sample}\\tSM:{wildcards.sample}' -p -t {THREADS} {input.sv_reference} - 2> {log} | samblaster --removeDups | k8 /net/eichler/vol4/home/jlhudd/src/bwakit/bwa.kit/bwa-postalt.js {input.alts} | samtools view -S -h -f 0x2 -q 20 - | samtools sort -T {TMPDIR}/alignments.{wildcards.sample} -O bam -o {output.alignments}; samtools index {output.alignments}"""

#
# Prepare local assembly sequences and references.
#

rule bwa_index_combined_reference:
    input: "sv_reference.fasta"
    output: "sv_reference.fasta.bwt"
    shell: "bwa index {input}"

rule merge_reference_and_local_assemblies:
    input: GENOTYPER_CONFIG["sv_reference"], "local_assemblies_for_genotyping.fasta"
    output: "sv_reference.fasta"
    shell: "cat {input} > {output}"

#
# Get coordinates in BAM reference to search for SV-related reads.
#

def _get_reference_path_by_wildcards(wildcards):
    return GENOTYPER_CONFIG["bam_reference"][wildcards.reference]

rule find_positions_of_sv_sequences_in_bam_reference:
    input: sv_sequence_alignments="sv_sequences_in_reference/{reference}.bam", reference=_get_reference_path_by_wildcards
    output: "sv_sequences_in_reference/{reference}.bed"
    benchmark: "benchmarks/positions_of_sv_sequences_in_bam_reference/{reference}.txt"
    params: slop=SLOP_FOR_SV_SEQUENCE_POSITIONS
    shell: "bedtools bamtobed -i {input.sv_sequence_alignments} | bedtools slop -i stdin -g {input.reference}.fai -b {params.slop} | sort -k 1,1 -k 2,2n | bedtools merge -i stdin -d 0 > {output}"

rule map_sv_sequences_to_bam_reference:
    input: reference=_get_reference_path_by_wildcards, sequences="sv_sequences.fragmented.fasta"
    output: "sv_sequences_in_reference/{reference}.bam"
    benchmark: "benchmarks/sv_sequences_in_bam_reference/{reference}.txt"
    shell: "bwa mem -t {THREADS} {input.reference} {input.sequences} | samtools sort -o {output} -O bam -T /var/tmp/sv_sequences"

#
# Get sequences associated with SVs in fragments corresponding to Illumina
# reads.
#

rule fragment_sv_sequences:
    input: "sv_sequences.fasta"
    output: "sv_sequences.fragmented.fasta"
    params: window="500", slide="250"
    shell: "python {SNAKEMAKE_DIR}/scripts/fragment_fasta_records.py {input} {output} {params.window} --slide {params.slide}; touch {output}"

rule collect_sv_sequences:
    input: "sv_sequences/insertion.fasta", "sv_sequences/insertion_flanks_and_deletions.fasta"
    output: "sv_sequences.fasta"
    shell: "cat {input} > {output}"

rule get_insertion_sv_sequences:
    input: sv_calls="sv_calls.bed"
    output: "sv_sequences/insertion.fasta"
    shell: """awk '{{ if ($4 == "INS") {{ print ">"$1"_"$2"_"$3"_insertion"; print $6 }} }}' {input.sv_calls} > {output}"""

rule get_sv_sequences:
    input: positions="sv_sequence_positions.bed", sv_reference=GENOTYPER_CONFIG["sv_reference"]
    output: "sv_sequences/insertion_flanks_and_deletions.fasta"
    shell: "bedtools getfasta -fi {input.sv_reference} -bed {input.positions} -fo {output}"

rule collect_sv_sequence_positions:
    input: "sv_sequence_positions/insertion.bed", "sv_sequence_positions/deletion.bed"
    output: "sv_sequence_positions.bed"
    shell: "sort -k 1,1 -k 2,2n -m {input} | bedtools merge -i stdin -d 0 > {output}"

rule get_insertion_sv_sequence_positions:
    input: sv_calls="sv_calls.bed", sv_reference_lengths=GENOTYPER_CONFIG["sv_reference_lengths"]
    output: "sv_sequence_positions/insertion.bed"
    params: slop=SLOP_FOR_SV_SEQUENCE_POSITIONS
    shell: """awk '$4 == "INS"' {input.sv_calls} | awk 'OFS="\\t" {{ print $1,$2,$2+1 }}' | bedtools slop -i stdin -g {input.sv_reference_lengths} -b {params.slop} | sort -k 1,1 -k 2,2n | bedtools merge -i stdin -d 0 > {output}"""

rule get_deletion_sv_sequence_positions:
    input: sv_calls="sv_calls.bed", sv_reference_lengths=GENOTYPER_CONFIG["sv_reference_lengths"]
    output: "sv_sequence_positions/deletion.bed"
    params: slop=SLOP_FOR_SV_SEQUENCE_POSITIONS
    shell: """awk '$4 == "DEL"' {input.sv_calls} | cut -f 1-3 | bedtools slop -i stdin -g {input.sv_reference_lengths} -b {params.slop} | bedtools merge -i stdin -d 0 > {output}"""

#
# Prepare SV calls from local assemblies.
#
# The final output of this step are the files:
#  - local_assemblies_for_genotyping.fasta

# Index assemblies.
rule index_assemblies:
    input: "local_assemblies_for_genotyping.fasta"
    output: "local_assemblies_for_genotyping.fasta.fai"
    shell: "samtools faidx {input}"

rule get_sequences_for_local_assemblies:
    input: "local_assemblies_for_genotyping.bam"
    output: "local_assemblies_for_genotyping.fasta"
    shell: """samtools bam2fq {input} | seqtk seq -A - > {output}"""

rule get_sam_of_local_assemblies_for_genotyping:
    input: "local_assemblies_for_genotyping.bam"
    output: "local_assemblies_for_genotyping.sam"
    shell: "samtools view -h {input} > {output}"

rule get_bam_of_local_assemblies_for_genotyping:
    input: local_assemblies=GENOTYPER_CONFIG["local_assembly_alignments"], calls="local_assembly_contigs_for_genotyping.txt"
    output: "local_assemblies_for_genotyping.bam"
    shell: "python {SNAKEMAKE_DIR}/scripts/filter_bam_by_query_name.py {input.local_assemblies} {input.calls} {output}; samtools index {output}"

rule get_local_assembly_contigs_for_genotyping:
    input: "sv_calls.vcf.gz"
    output: "local_assembly_contigs_for_genotyping.txt"
    run:
        with pysam.VariantFile(input[0]) as vcf:
            with open(output[0], "w") as oh:
                for contig in sorted(set([record.info["CONTIG"] for record in vcf])):
                    oh.write("%s\n" % contig)

rule get_svs_in_bed_format:
    input: "sv_calls.vcf.gz"
    output: "sv_calls.bed"
    run:
        record_count = 0

        with pysam.VariantFile(input[0]) as vcf:
            with open(output[0], "w") as oh:
                for record in vcf:
                    record_count += 1

                    if isinstance(record.info["SVLEN"], tuple):

                        # Work around pysam bug when SVLEN == -127 (https://github.com/pysam-developers/pysam/issues/371)
                        if len(record.info["SVLEN"]) == 0:
                            sv_length = record.info['END'] - record.pos + 1
                        else:
                            sv_length = abs(record.info["SVLEN"][0])
                    else:
                        sv_length = abs(record.info["SVLEN"])

                    oh.write("%s\n" % "\t".join(map(str, (
                        record.chrom,
                        record.start,
                        record.info["END"],
                        record.info["SVTYPE"],
                        sv_length,
                        record.info["SEQ"]
                    ))))

rule filter_variants_to_only_svs:
    input: GENOTYPER_CONFIG["sv_calls"]
    output: "sv_calls.vcf.gz"
    shell: """bcftools filter -O z -i "(SVTYPE='INS' | SVTYPE='DEL') & (SVLEN >= 50 | (SVTYPE='DEL' & SVLEN <= -50))" {input} > {output}; tabix -p vcf {output}"""
